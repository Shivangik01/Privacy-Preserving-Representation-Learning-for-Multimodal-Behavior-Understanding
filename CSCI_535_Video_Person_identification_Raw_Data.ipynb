{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhvmEke51zqg",
        "outputId": "b7244e16-8f82-405e-cc6a-4dabae13e8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "zXuFxZwY18Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDkmx_Nk6yU0"
      },
      "outputs": [],
      "source": [
        "#frames, id = [], []\n",
        "path = \"/content/drive/MyDrive/Multimodal Project/finals/CREMAD/videos\"\n",
        "op_path = \"/content/drive/MyDrive/Multimodal Project/finals/CREMAD/id_data\"\n",
        "for file_name in os.listdir(path):\n",
        "    identity = file_name.split(\"_\")[0]\n",
        "    emotion = file_name.split(\"_\")[2]\n",
        "    output_path = os.path.join(op_path, identity)\n",
        "    if not os.path.exists(output_path):\n",
        "      os.makedirs(output_path)\n",
        "    video_path = os.path.join(path, file_name)\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    i = 0\n",
        "    frame_number = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_number % 5 == 0:\n",
        "          loc = os.path.join(output_path, f\"{emotion}_{i}.jpg\")\n",
        "          cv2.imwrite(loc, frame)\n",
        "          i += 1\n",
        "        frame_number += 1\n",
        "        # id.append(identity)\n",
        "        # frames.append(np.array(img_to_array(frame) / 255.0))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Multimodal Project/finals/CREMAD/id_data\"\n",
        "labels = os.listdir(path)\n",
        "train_df, test_df, val_df = [], [], []\n",
        "for l in labels:\n",
        "  imgs = os.listdir(path+\"/\"+l)\n",
        "  ni = len(imgs)\n",
        "  train_size = math.ceil(0.7*ni)\n",
        "  val_size = math.ceil(0.15*ni)\n",
        "  test_size = ni - train_size - val_size\n",
        "  train, test = train_test_split(imgs, test_size = test_size, shuffle = True)\n",
        "  train, val = train_test_split(train, train_size = train_size, shuffle = True)\n",
        "  for img in train:\n",
        "    img_path = path+\"/\"+l+\"/\"+img\n",
        "    train_df.append([str(img_path),l])\n",
        "  for img in test:\n",
        "    img_path = path+\"/\"+l+\"/\"+img\n",
        "    test_df.append([str(img_path),l])\n",
        "  for img in val:\n",
        "    img_path = path+\"/\"+l+\"/\"+img\n",
        "    val_df.append([str(img_path),l])\n",
        "\n",
        "train_df = pd.DataFrame(train_df, columns =['path', 'label'])\n",
        "test_df = pd.DataFrame(test_df, columns =['path', 'label'])\n",
        "val_df = pd.DataFrame(val_df, columns =['path', 'label'])"
      ],
      "metadata": {
        "id": "eyWewlLZB2Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator()\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
        "                                                    x_col='path',\n",
        "                                                    y_col='label',\n",
        "                                                    batch_size=64,class_mode='sparse')\n",
        "val_datagen = ImageDataGenerator()\n",
        "val_generator = val_datagen.flow_from_dataframe(dataframe=val_df,\n",
        "                                                x_col='path',\n",
        "                                                y_col='label',\n",
        "                                                batch_size=64,\n",
        "                                                shuffle=False,\n",
        "                                                class_mode='sparse')\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\n",
        "                                                  x_col='path',\n",
        "                                                  y_col='label',\n",
        "                                                  batch_size=64,\n",
        "                                                  shuffle=False,\n",
        "                                                  class_mode='sparse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCc-FDpVCNCU",
        "outputId": "36082696-eca1-413c-bac0-fe57d01b4848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2905 validated image filenames belonging to 91 classes.\n",
            "Found 661 validated image filenames belonging to 91 classes.\n",
            "Found 529 validated image filenames belonging to 91 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "\n",
        "vgg16_model = VGG16(pooling='avg', weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "for layers in vgg16_model.layers:\n",
        "            layers.trainable=False\n",
        "last_output = vgg16_model.layers[-1].output\n",
        "vgg_x = Flatten()(last_output)\n",
        "vgg_x = Dense(128, activation = 'relu')(vgg_x)\n",
        "vgg_x=BatchNormalization()(vgg_x)\n",
        "vgg_x=Dropout(0.2)(vgg_x)\n",
        "vgg_x = Dense(91, activation = 'softmax')(vgg_x)\n",
        "vgg16_model = Model(vgg16_model.input, vgg_x)\n",
        "vgg16_model.compile(loss = 'sparse_categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "history = vgg16_model.fit(train_generator,\n",
        "                    validation_data=val_generator,\n",
        "                    epochs=20,\n",
        "                    callbacks=[early_stopping],\n",
        "                    verbose=1)\n",
        "vgg16_model.save_weights('/content/drive/MyDrive/Multimodal Project/finals/vgg16.h5')\n",
        "\n",
        "# Evaluate the model on training and test sets\n",
        "train_loss, train_acc = vgg16_model.evaluate(train_generator, verbose=0)\n",
        "\n",
        "print('Train accuracy:', train_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMfC4RkVD1tl",
        "outputId": "b10c45ff-b320-4602-c870-51b51c0b1669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "46/46 [==============================] - 54s 812ms/step - loss: 3.0343 - accuracy: 0.4124 - val_loss: 2.1503 - val_accuracy: 0.5008\n",
            "Epoch 2/20\n",
            "46/46 [==============================] - 26s 552ms/step - loss: 1.0201 - accuracy: 0.9384 - val_loss: 0.6331 - val_accuracy: 0.9864\n",
            "Epoch 3/20\n",
            "46/46 [==============================] - 25s 550ms/step - loss: 0.3427 - accuracy: 0.9983 - val_loss: 0.2309 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "46/46 [==============================] - 26s 559ms/step - loss: 0.1546 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "46/46 [==============================] - 27s 587ms/step - loss: 0.0861 - accuracy: 0.9997 - val_loss: 0.0726 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "46/46 [==============================] - 27s 578ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "46/46 [==============================] - 27s 577ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "46/46 [==============================] - 28s 605ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "46/46 [==============================] - 26s 565ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "46/46 [==============================] - 27s 578ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "46/46 [==============================] - 26s 557ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "46/46 [==============================] - 26s 562ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "46/46 [==============================] - 26s 559ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "46/46 [==============================] - 26s 555ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "46/46 [==============================] - 26s 573ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "46/46 [==============================] - 27s 586ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "46/46 [==============================] - 31s 675ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "46/46 [==============================] - 26s 563ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "46/46 [==============================] - 27s 573ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "46/46 [==============================] - 25s 535ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Train accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification report for testing\n",
        "test_predIdxs = vgg16_model.predict_generator(test_generator)\n",
        "test_predIdxs = np.argmax(test_predIdxs, axis=1)\n",
        "print(classification_report(test_generator.labels, test_predIdxs, target_names=[l for l in labels]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p33L5g_fEYYw",
        "outputId": "2918ca2f-f755-4c42-df5c-5eb687fe9d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-52463c944575>:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  test_predIdxs = vgg16_model.predict_generator(test_generator)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        1001       1.00      1.00      1.00         4\n",
            "        1003       1.00      1.00      1.00         6\n",
            "        1004       1.00      1.00      1.00         6\n",
            "        1002       1.00      1.00      1.00        10\n",
            "        1006       1.00      1.00      1.00         6\n",
            "        1005       1.00      1.00      1.00         5\n",
            "        1008       1.00      1.00      1.00         5\n",
            "        1009       1.00      1.00      1.00         7\n",
            "        1007       1.00      1.00      1.00         8\n",
            "        1015       1.00      1.00      1.00         6\n",
            "        1012       1.00      1.00      1.00         8\n",
            "        1010       1.00      1.00      1.00         6\n",
            "        1014       1.00      1.00      1.00         5\n",
            "        1011       1.00      1.00      1.00         5\n",
            "        1016       1.00      1.00      1.00         5\n",
            "        1017       1.00      1.00      1.00         7\n",
            "        1013       1.00      1.00      1.00         5\n",
            "        1022       1.00      1.00      1.00         7\n",
            "        1021       1.00      1.00      1.00         4\n",
            "        1019       1.00      1.00      1.00         6\n",
            "        1020       1.00      1.00      1.00         9\n",
            "        1018       1.00      1.00      1.00         6\n",
            "        1029       1.00      1.00      1.00         5\n",
            "        1025       1.00      1.00      1.00         5\n",
            "        1032       1.00      1.00      1.00         7\n",
            "        1026       1.00      1.00      1.00         6\n",
            "        1030       1.00      1.00      1.00         7\n",
            "        1027       1.00      1.00      1.00         6\n",
            "        1028       1.00      1.00      1.00         5\n",
            "        1031       1.00      1.00      1.00         6\n",
            "        1023       1.00      1.00      1.00         5\n",
            "        1024       1.00      1.00      1.00         5\n",
            "        1037       1.00      1.00      1.00         5\n",
            "        1035       1.00      1.00      1.00         5\n",
            "        1038       1.00      1.00      1.00         5\n",
            "        1033       1.00      1.00      1.00         7\n",
            "        1036       1.00      1.00      1.00         5\n",
            "        1040       1.00      1.00      1.00         6\n",
            "        1034       1.00      1.00      1.00         5\n",
            "        1041       1.00      1.00      1.00         6\n",
            "        1043       1.00      1.00      1.00         5\n",
            "        1044       1.00      1.00      1.00         7\n",
            "        1039       1.00      1.00      1.00         5\n",
            "        1042       1.00      1.00      1.00         7\n",
            "        1045       1.00      1.00      1.00         6\n",
            "        1046       1.00      1.00      1.00         5\n",
            "        1047       1.00      1.00      1.00         6\n",
            "        1048       1.00      1.00      1.00         5\n",
            "        1049       1.00      1.00      1.00         6\n",
            "        1054       1.00      1.00      1.00         5\n",
            "        1053       1.00      1.00      1.00         6\n",
            "        1055       1.00      1.00      1.00         7\n",
            "        1056       1.00      1.00      1.00         5\n",
            "        1051       1.00      1.00      1.00         6\n",
            "        1052       1.00      1.00      1.00         5\n",
            "        1050       1.00      1.00      1.00         5\n",
            "        1057       1.00      1.00      1.00         7\n",
            "        1063       1.00      1.00      1.00         6\n",
            "        1062       1.00      1.00      1.00         6\n",
            "        1061       1.00      1.00      1.00         6\n",
            "        1060       1.00      1.00      1.00         4\n",
            "        1064       1.00      1.00      1.00         5\n",
            "        1059       1.00      1.00      1.00         5\n",
            "        1058       1.00      1.00      1.00         8\n",
            "        1065       1.00      1.00      1.00         5\n",
            "        1066       1.00      1.00      1.00         5\n",
            "        1068       1.00      1.00      1.00         7\n",
            "        1067       1.00      1.00      1.00         8\n",
            "        1069       1.00      1.00      1.00         5\n",
            "        1075       1.00      1.00      1.00         6\n",
            "        1070       1.00      1.00      1.00         5\n",
            "        1072       1.00      1.00      1.00         5\n",
            "        1076       1.00      1.00      1.00         6\n",
            "        1074       1.00      1.00      1.00         5\n",
            "        1073       1.00      1.00      1.00         6\n",
            "        1071       1.00      1.00      1.00         5\n",
            "        1077       1.00      1.00      1.00         6\n",
            "        1078       1.00      1.00      1.00         5\n",
            "        1082       1.00      1.00      1.00         5\n",
            "        1079       1.00      1.00      1.00         6\n",
            "        1084       1.00      1.00      1.00         7\n",
            "        1080       1.00      1.00      1.00         5\n",
            "        1083       1.00      1.00      1.00         7\n",
            "        1081       1.00      1.00      1.00         5\n",
            "        1088       1.00      1.00      1.00         5\n",
            "        1091       1.00      1.00      1.00         6\n",
            "        1090       1.00      1.00      1.00         8\n",
            "        1085       1.00      1.00      1.00         6\n",
            "        1087       1.00      1.00      1.00         5\n",
            "        1086       1.00      1.00      1.00         5\n",
            "        1089       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00       529\n",
            "   macro avg       1.00      1.00      1.00       529\n",
            "weighted avg       1.00      1.00      1.00       529\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsatZRXCM5PJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}